{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9章 潜在顧客を把握するための画像認識１０本\n",
    "\n",
    "ここでは、カメラから取得した映像を用いて画像認識を行い、  \n",
    "必要な情報を取得するための流れを学ぶことで、  \n",
    "画像認識をビジネス現場で応用するイメージをつかみます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ノック８１：画像データを読み込んでみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image width:1920\n",
      "image height:1440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img=cv2.imread('img/img01.jpg')\n",
    "height, width = img.shape[:2]\n",
    "print('image width:{}'.format(width))\n",
    "print('image height:{}'.format(height))\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 1920)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ノック８２：映像データを読み込んでみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image width:1920.0\n",
      "image height:1440.0\n",
      "frame count total:401.0\n",
      "image fpt:30.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('mov/mov01.avi')\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print ('image width:{}'.format(width))\n",
    "print('image height:{}'.format(height))\n",
    "print('frame count total:{}'.format(count))\n",
    "print('image fpt:{}'.format(fps))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ノック８３：映像を画像に分割し、保存してみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('mov/mov01.avi')\n",
    "\n",
    "num = 0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow('frame', frame)\n",
    "        filepath = 'snapshot/snapshot_'+str(num)+'.jpg'\n",
    "        cv2.imwrite(filepath, frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    num += 1\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ノック８４：画像内のどこに人がいるのかを検出してみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# preparing\n",
    "hog= cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "hogParams = {'winStride': (8,8), 'padding':(32,32), 'scale':1.05, 'hitThreshold':0, 'finalThreshold':5}\n",
    "\n",
    "# detection\n",
    "img = cv2.imread('img/img01.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "human, r = hog.detectMultiScale(gray, **hogParams)\n",
    "if (len(human)>0):\n",
    "    for (x, y, w, h) in human:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255,255,255),3)\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ノック８５：画像内の人の顔を検出してみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# preparing\n",
    "cascade_file = 'haarcascade_frontalface_alt.xml'\n",
    "cascade = cv2.CascadeClassifier(cascade_file)\n",
    "\n",
    "# detect\n",
    "img = cv2.imread('img/img02.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "face_list = cascade.detectMultiScale(gray, minSize=(50,50))\n",
    "\n",
    "# mark by detected faces\n",
    "for (x, y, w, h) in face_list:\n",
    "    color = (0,0,225)\n",
    "    pen_w = 3\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), color, thickness=pen_w)\n",
    "cv2.imshow('img', img)\n",
    "cv2.imwrite('temp.jpg', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ノック８６：画像内の人がどこに顔を向けているのかを検出してみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-9c339c931967>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# preparing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dlib'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import math\n",
    "\n",
    "# preparing\n",
    "predictor = dlib.shape_predictor('shape_predctor_68_face_landmarks.dat')\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# detect\n",
    "img = cv2.imread('img/img02.jpg')\n",
    "dets = detector(img, 1)\n",
    "\n",
    "for k, d in enumerate(dets):\n",
    "    shape = predictor(img, d)\n",
    "    \n",
    "    # display of face area\n",
    "    color_f = (0,0,225)\n",
    "    color_l_out = (255,0,0)\n",
    "    color_l_in =(0,255,0)\n",
    "    line_w = 3\n",
    "    circle_r =3\n",
    "    fontType = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    fontSize = 1\n",
    "    cv2.rectangle(img, (d.left(), d.top()), (d.right(), d.bottom()), color_f, line_w)\n",
    "    cv2.putText(img, str(k), (d.left(), d.top()), fontType, fontSize, color_f, line_w)\n",
    "    \n",
    "    # preparing gravity\n",
    "    num_of_points_out = 17\n",
    "    num_of_points_in = shape.num_parts-num_of_points_out\n",
    "    gx_out=0\n",
    "    gy_out=0\n",
    "    gx_in=0\n",
    "    gy_in=0\n",
    "    for shape_point_count in range(shape.num_parts):\n",
    "        shape_point = shape.part(shape_point_count)\n",
    "        \n",
    "        if shape_point_count<num_of_points_out:\n",
    "            cv2.circle(img, (shape_point.x, shape_point.y), circle_r, color_l_out, line_w)\n",
    "            gx_out = gx_out+shape_point.x/num_of_points_out\n",
    "            gy_out = gy_out_shape_point.y/num_of_points_out\n",
    "        else:\n",
    "            cv2.cirble(img, (shape_point.x, shape_point.y), circle_r, color_l_in, line_w)\n",
    "            gx_in = gx_in + shape_point.x/num_of_points_in\n",
    "            gy_in = gy_in + shape_point.y/num_of_points_in\n",
    "        \n",
    "    cv2.circle(img, (int(gx_out), int(gy_out)), circle_r, (0,0,255), line_w)\n",
    "    cv2.circle(img, (int(gx_in), int(gy_in)), circle_r, (0,0,0), line_w)\n",
    "    \n",
    "    # calculate of face direction\n",
    "    theta = math.asin(2*(gx_in-gx_out)/(d.right()-d.left()))\n",
    "    radian = theta*180/math.pi\n",
    "    \n",
    "    print('face direction:{} (radian:{})'.format(theta, radian))\n",
    "    \n",
    "    if radian<0:\n",
    "        textPrefix = \"   left\"\n",
    "    else:\n",
    "        textPrefix = '   right'\n",
    "        \n",
    "    textShow = txtPrefix + str(round(abs(radian), 1)) + ' deg.'\n",
    "    cv2.putText(img, textShow, (d.left(), d.top()), fontType, fontSize, color_f, line_w)\n",
    "    \n",
    "cv2.imshow('img', img)\n",
    "cv2.imwrite('temp.jpg', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ノック８７：検出した情報を統合し、タイムラプスを作ってみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ノック８８：全体像をグラフにして可視化してみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ノック８９：人通りの変化をグラフで確認しよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ノック９０：移動平均を計算することでノイズの影響を除去しよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
